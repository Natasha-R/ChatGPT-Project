**The purpose of this study is to analyse AI-generated code, with a focus on software engineering use-cases.** The seven core areas of this research are described below.

This dataset can also be accessed on the IEEE dataport: [https://dx.doi.org/10.21227/4rxb-zv06](https://dx.doi.org/10.21227/4rxb-zv06)

### [Analysis of AI and Student-written Code](Analysis%20of%20AI%20and%20Student-written%20Code)

AI chatbots (ChatGPT-4, ChatGPT-3.5, Bing Chat and Bard) were used to generate code solutions to Java programming tasks (milestone assignments) taken from the 2021 presentation of the [Software Engineering 2](https://www.archi-lab.io/regularModules/ss22/st2_ss22.html) Bachelor's course at TH KÃ¶ln. Student solutions to the same assignments were stored anonymously. The differences between the AI and human written code solutions to "milestone 0" are analysed, and a simple classification model was trained to distinguish between AI and human written code. For the analysis, two approaches are compared: representing the code using manually defined features, and by OpenAI's text embedding vectors.

### [AI or Student-written Code Predictions](AI%20or%20Student-written%20Code%20Predictions)

In order to determine how effectively AI-written code can be detected "by eye", a mixed set of AI- and human-written code solutions to the "Software Engineering 2" 2021 milestone 0 assignment was anonymised and given to two faculty members, who made predictions as to whether each solution was written by either a student or AI chatbot.

### [Analysis of AI and Human-written Python Code](Analysis%20of%20AI%20and%20Human-written%20Python%20Code)

ChatGPT was used to generate Python code solutions to the [HumanEval](https://github.com/openai/human-eval) problem set. The differences between the AI and human-written canonical code solutions are analysed, and a model is trained to distinguish between the two classes. The feature and embedding representation approaches are compared.

### [ChatGPT Capabilities Experiment](ChatGPT%20Capabilities%20Experiment)

An evaluation of the capabilities of ChatGPT at completing software engineering university course assignments. By prompting ChatGPT-4 with only the original task description and provided document comments, purely AI-written code was generated as the solution to the "Software Engineering 2" 2023 assignment, comprising of the creation of a complex eCommerce system.

### [Student Experiences with ChatGPT](Student%20Experiences%20with%20ChatGPT)

Feedback from two students on their experiences with using ChatGPT during their software engineering studies. Each use-case is evaluated, and the conversation with ChatGPT is provided.

### [AI Tools Experiences and Guidelines](AI%20Tools%20Experiences%20and%20Guidelines)

Our experiences with generating code using different chatbots, an evaluation of their strengths and weaknesses, and a set of guidelines for using AI tools to write code.

### [Student Survey](Student%20Survey)

The results from a survey distributed to university students. Questions relate to general AI tool use, AI use within education, and AI use specifically for coding and software engineering.



