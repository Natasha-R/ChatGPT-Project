{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c67d8ea-79c7-40fd-85a5-944895ae1e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import astroid\n",
    "import ast\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from radon.complexity import cc_visit_ast\n",
    "from radon.metrics import h_visit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ac72ce-ab0c-4b2d-b909-600a2397090e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"detection_sample_data.csv\")\n",
    "data = data[[\"Problem_ID\", \"Canonical_Solution\", \"GPT4_Solution\"]]\n",
    "data.columns = [\"problem_id\", \"human\", \"gpt4\"]\n",
    "data = pd.melt(data, id_vars=\"problem_id\", var_name=\"source\", value_name=\"code\")\n",
    "data[\"cleaned_code\"] = data[\"code\"].apply(lambda row: (re.sub(r\" *#.*\\n\", \"\\n\", \"\\n\".join([value for value in row[4:].replace(\"\\n    \", \"\\n\").splitlines() if len(value.lstrip())==0 or value.lstrip()[0] != \"#\"]))).lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3b21e2-0762-44b7-a62d-3c854a79029b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(data=data, code_column=\"cleaned_code\", has_comments=False):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data[\"num_chars\"] = data[code_column].str.len()\n",
    "    data[\"num_lines\"] = data[code_column].apply(lambda row: len(row.splitlines()))\n",
    "    data[\"avg_line_length\"] = data[code_column].apply(lambda row: np.mean([len(line) for line in row.splitlines() if len(line)>0]))\n",
    "    data[\"max_line_length\"] = data[code_column].apply(lambda row: max([len(line) for line in row.splitlines() if len(line)>0]))\n",
    "    data[\"num_digits\"] = (data[code_column].apply(lambda row: len([value for value in row if value.isdigit()])))\n",
    "    data[\"num_empty_lines\"] = data[code_column].str.count(\"\\n\\n\")\n",
    "    data[\"num_method_declarations\"] = data[code_column].str.count(\"def\")\n",
    "    data[\"num_local_vars\"] = data[code_column].apply(lambda code: len({node.targets[0].as_string() for node in astroid.parse(code).nodes_of_class(astroid.Assign)}))\n",
    "    data[\"avg_name_length\"] = data[code_column].apply(lambda code: np.mean(list({len(node.targets[0].as_string()) for node in astroid.parse(code).nodes_of_class(astroid.Assign)})))\n",
    "    data[\"max_name_length\"] = data[code_column].apply(lambda code: max(list({len(node.targets[0].as_string()) for node in astroid.parse(code).nodes_of_class(astroid.Assign)}), default=0))\n",
    "    data[\"num_function_calls\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Call))))\n",
    "    data[\"num_loops\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.For))) + len(list(astroid.parse(code).nodes_of_class(astroid.While))))\n",
    "    data[\"num_if_statements\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.If))))\n",
    "    data[\"num_return_statements\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Return))))\n",
    "    data[\"num_exceptions_raised\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Raise))))\n",
    "    data[\"num_list_comprehensions\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.ListComp))))\n",
    "    data[\"num_dict_comprehensions\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.DictComp))))\n",
    "    data[\"num_set_comprehensions\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.SetComp))))\n",
    "    data[\"num_imported_modules\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Import))))\n",
    "    data[\"num_list_operations\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.List))))\n",
    "    data[\"num_dict_operations\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Dict))))\n",
    "    data[\"num_set_operations\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Set))))\n",
    "    data[\"num_lambda_functions\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Lambda))))\n",
    "    data[\"num_generator_expressions\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.GeneratorExp))))\n",
    "    data[\"num_attributes_accessed\"] = data[code_column].apply(lambda code: len(list(astroid.parse(code).nodes_of_class(astroid.Attribute))))\n",
    "    data[\"cyclomatic_complexity\"] = data[code_column].apply(lambda code: sum(item.complexity for item in cc_visit_ast(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\"))))))\n",
    "    data[\"halstead_operators\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.h1)\n",
    "    data[\"halstead_operands\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.h2)\n",
    "    data[\"halstead_length\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.calculated_length)\n",
    "    data[\"halstead_volume\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.volume)\n",
    "    data[\"halstead_difficulty\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.difficulty)\n",
    "    data[\"halstead_effort\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.effort)\n",
    "    data[\"halstead_time\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.time)\n",
    "    data[\"halstead_bugs\"] = data[code_column].apply(lambda code: h_visit(ast.parse(f\"def temp():\\n\" + \"\\n\".join(f\"    {line}\" for line in code.split(\"\\n\")))).total.bugs)\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    if has_comments:\n",
    "        data[\"num_comments\"] = data[code_column].str.count(\"#\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a4f124-45b6-46e8-b185-6693c55e4c24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "feature_data = extract_features(data, \"cleaned_code\").iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0098495-603d-4870-af0b-3eacd29c4f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b|\\S\", lowercase=True)\n",
    "bag_of_words = vectorizer.fit_transform(list(data[\"cleaned_code\"]))\n",
    "bow_data = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93d3832b-77a6-45ca-b7df-040b0f90d4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_features = pd.concat([feature_data, bow_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e16798c-6730-41b2-adfe-ee70e07eba72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_features.values, data[\"source\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d2927dd-cc3c-40af-93d6-f95d35c4880a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 47.5 %\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(random_state=0, n_estimators=160, max_features=\"sqrt\")\n",
    "forest_model.fit(X_train, y_train)\n",
    "print(\"Accuracy on test set:\", np.round(accuracy_score(y_test, forest_model.predict(X_test)), 3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "102b7f9c-ab08-42b8-a348-df2ce9be3807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 46.5 %\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=5000)\n",
    "log_model.fit(X_train, y_train)\n",
    "print(\"Accuracy on test set:\", np.round(accuracy_score(y_test, log_model.predict(X_test)), 3)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
